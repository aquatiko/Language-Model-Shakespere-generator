{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare-Language-Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "YKcZaKozYh_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!mkdir gdrive\n",
        "!google-drive-ocamlfuse gdrive\n",
        "!ls gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3o7MDrJQ6lU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file= open('poemShakespeare.txt').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEDFlbsWRWjO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raw_text= file.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSp3XxGQRX6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok= raw_text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hSLCr09Rzy9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text=\"\"\n",
        "for i in tok:\n",
        "  text+= i+ \" \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oiIcD4MPSZgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "11494659-6793-4dc3-986f-3db2b05313d6"
      },
      "cell_type": "code",
      "source": [
        "text"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"a lover's complaint from off a hill whose concave womb reworded a plaintful story from a sistering vale, my spirits to attend this double voice accorded, and down i laid to list the sad-tuned tale; ere long espied a fickle maid full pale, 5 tearing of papers, breaking rings a-twain, storming her world with sorrow's wind and rain. upon her head a platted hive of straw, which fortified her visage from the sun, whereon the thought might think sometime it saw 10 the carcass of beauty spent and done: time had not scythed all that youth begun, nor youth all quit; but, spite of heaven's fell rage, some beauty peep'd through lattice of sear'd age. oft did she heave her napkin to her eyne, 15 which on it had conceited characters, laundering the silken figures in the brine that season'd woe had pelleted in tears, and often reading what contents it bears; as often shrieking undistinguish'd woe, 20 in clamours of all size, both high and low. sometimes her levell'd eyes their carriage ride, as they did battery to the spheres intend; sometime diverted their poor balls are tied to the orbed earth; sometimes they do extend 25 their view right on; anon their gazes lend to every place at once, and, nowhere fix'd, the mind and sight distractedly commix'd. her hair, nor loose nor tied in formal plat, proclaim'd in her a careless hand of pride 30 for some, untuck'd, descended her sheaved hat, hanging her pale and pined cheek beside; some in her threaden fillet still did bide, and true to bondage would not break from thence, though slackly braided in loose negligence. 35 a thousand favours from a maund she drew of amber, crystal, and of beaded jet, which one by one she in a river threw, upon whose weeping margent she was set; like usury, applying wet to wet, 40 or monarch's hands that let not bounty fall where want cries some, but where excess begs all. of folded schedules had she many a one, which she perused, sigh'd, tore, and gave the flood; crack'd many a ring of posied gold and bone 45 bidding them find their sepulchres in mud; found yet moe letters sadly penn'd in blood, with sleided silk feat and affectedly enswathed, and seal'd to curious secrecy. these often bathed she in her fluxive eyes, 50 and often kiss'd, and often 'gan to tear: cried 'o false blood, thou register of lies, what unapproved witness dost thou bear! ink would have seem'd more black and damned here!' this said, in top of rage the lines she rents, 55 big discontent so breaking their contents. a reverend man that grazed his cattle nigh-- sometime a blusterer, that the ruffle knew of court, of city, and had let go by the swiftest hours, observed as they flew-- 60 towards this afflicted fancy fastly drew, and, privileged by age, desires to know in brief the grounds and motives of her woe. so slides he down upon his grained bat, and comely-distant sits he by her side; 65 when he again desires her, being sat, her grievance with his hearing to divide: if that from him there may be aught applied which may her suffering ecstasy assuage, 'tis promised in the charity of age. 70 'father,' she says, 'though in me you behold the injury of many a blasting hour, let it not tell your judgment i am old; not age, but sorrow, over me hath power: i might as yet have been a spreading flower, 75 fresh to myself, if i had self-applied love to myself and to no love beside. 'but, woe is me! too early i attended a youthful suit--it was to gain my grace-- of one by nature's outwards so commended, 80 that maidens' eyes stuck over all his face: love lack'd a dwelling, and made him her place; and when in his fair parts she did abide, she was new lodged and newly deified. 'his browny locks did hang in crooked curls; 85 and every light occasion of the wind upon his lips their silken parcels hurls. what's sweet to do, to do will aptly find: each eye that saw him did enchant the mind, for on his visage was in little drawn 90 what largeness thinks in paradise was sawn. 'small show of man was yet upon his chin; his phoenix down began but to appear like unshorn velvet on that termless skin whose bare out-bragg'd the web it seem'd to wear: 95 yet show'd his visage by that cost more dear; and nice affections wavering stood in doubt if best were as it was, or best without. 'his qualities were beauteous as his form, for maiden-tongued he was, and thereof free; 100 yet, if men moved him, was he such a storm as oft 'twixt may and april is to see, when winds breathe sweet, untidy though they be. his rudeness so with his authorized youth did livery falseness in a pride of truth. 105 'well could he ride, and often men would say 'that horse his mettle from his rider takes: proud of subjection, noble by the sway, what rounds, what bounds, what course, what stop he makes!' 110 and controversy hence a question takes, whether the horse by him became his deed, or he his manage by the well-doing steed. 'but quickly on this side the verdict went: his real habitude gave life and grace 115 to appertainings and to ornament, accomplish'd in himself, not in his case: all aids, themselves made fairer by their place, came for additions; yet their purposed trim pieced not his grace, but were all graced by him. 120 'so on the tip of his subduing tongue all kinds of arguments and question deep, all replication prompt, and reason strong, for his advantage still did wake and sleep: to make the weeper laugh, the laugher weep, 125 he had the dialect and different skill, catching all passions in his craft of will: 'that he did in the general bosom reign of young, of old; and sexes both enchanted, to dwell with him in thoughts, or to remain 130 in personal duty, following where he haunted: consents bewitch'd, ere he desire, have granted; and dialogued for him what he would say, ask'd their own wills, and made their wills obey. 'many there were that did his picture get, 135 to serve their eyes, and in it put their mind; like fools that in th' imagination set the goodly objects which abroad they find of lands and mansions, theirs in thought assign'd; and labouring in moe pleasures to bestow them 140 than the true gouty landlord which doth owe them: 'so many have, that never touch'd his hand, sweetly supposed them mistress of his heart. my woeful self, that did in freedom stand, and was my own fee-simple, not in part, 145 what with his art in youth, and youth in art, threw my affections in his charmed power, reserved the stalk and gave him all my flower. 'yet did i not, as some my equals did, demand of him, nor being desired yielded; 150 finding myself in honour so forbid, with safest distance i mine honour shielded: experience for me many bulwarks builded of proofs new-bleeding, which remain'd the foil of this false jewel, and his amorous spoil. 155 'but, ah, who ever shunn'd by precedent the destined ill she must herself assay? or forced examples, 'gainst her own content, to put the by-past perils in her way? counsel may stop awhile what will not stay; 160 for when we rage, advice is often seen by blunting us to make our wits more keen. 'nor gives it satisfaction to our blood, that we must curb it upon others' proof; to be forbod the sweets that seem so good, 165 for fear of harms that preach in our behoof. o appetite, from judgment stand aloof! the one a palate hath that needs will taste, though reason weep, and cry, 'it is thy last.' 'for further i could say 'this man's untrue,' 170 and knew the patterns of his foul beguiling; heard where his plants in others' orchards grew, saw how deceits were gilded in his smiling; knew vows were ever brokers to defiling; thought characters and words merely but art, 175 and bastards of his foul adulterate heart. 'and long upon these terms i held my city, till thus he gan besiege me: 'gentle maid, have of my suffering youth some feeling pity, and be not of my holy vows afraid: 180 that's to ye sworn to none was ever said; for feasts of love i have been call'd unto, till now did ne'er invite, nor never woo. 'all my offences that abroad you see are errors of the blood, none of the mind; 185 love made them not: with acture they may be, where neither party is nor true nor kind: they sought their shame that so their shame did find; and so much less of shame in me remains, by how much of me their reproach contains. 190 'among the many that mine eyes have seen, not one whose flame my heart so much as warm'd, or my affection put to the smallest teen, or any of my leisures ever charm'd: harm have i done to them, but ne'er was harm'd; 195 kept hearts in liveries, but mine own was free, and reign'd, commanding in his monarchy. 'look here, what tributes wounded fancies sent me, of paled pearls and rubies red as blood; figuring that they their passions likewise lent me 200 of grief and blushes, aptly understood in bloodless white and the encrimson'd mood; effects of terror and dear modesty, encamp'd in hearts, but fighting outwardly. 'and, lo, behold these talents of their hair, 205 with twisted metal amorously impleach'd, i have received from many a several fair, their kind acceptance weepingly beseech'd, with the annexions of fair gems enrich'd, and deep-brain'd sonnets that did amplify 210 each stone's dear nature, worth, and quality. 'the diamond,--why, 'twas beautiful and hard, whereto his invised properties did tend; the deep-green emerald, in whose fresh regard weak sights their sickly radiance do amend; 215 the heaven-hued sapphire and the opal blend with objects manifold: each several stone, with wit well blazon'd, smiled or made some moan. 'lo, all these trophies of affections hot, of pensived and subdued desires the tender, 220 nature hath charged me that i hoard them not, but yield them up where i myself must render, that is, to you, my origin and ender; for these, of force, must your oblations be, since i their altar, you enpatron me. 225 'o, then, advance of yours that phraseless hand, whose white weighs down the airy scale of praise; take all these similes to your own command, hallow'd with sighs that burning lungs did raise; what me your minister, for you obeys, 230 works under you; and to your audit comes their distract parcels in combined sums. 'lo, this device was sent me from a nun, or sister sanctified, of holiest note; which late her noble suit in court did shun, 235 whose rarest havings made the blossoms dote; for she was sought by spirits of richest coat, but kept cold distance, and did thence remove, to spend her living in eternal love. 'but, o my sweet, what labour is't to leave 240 the thing we have not, mastering what not strives, playing the place which did no form receive, playing patient sports in unconstrained gyves? she that her fame so to herself contrives, the scars of battle 'scapeth by the flight, 245 and makes her absence valiant, not her might. 'o, pardon me, in that my boast is true: the accident which brought me to her eye upon the moment did her force subdue, and now she would the caged cloister fly: 250 religious love put out religion's eye: not to be tempted, would she be immured, and now, to tempt, all liberty procured. 'how mighty then you are, o, hear me tell! the broken bosoms that to me belong 255 have emptied all their fountains in my well, and mine i pour your ocean all among: i strong o'er them, and you o'er me being strong, must for your victory us all congest, as compound love to physic your cold breast. 260 'my parts had power to charm a sacred nun, who, disciplined, ay, dieted in grace, believed her eyes when they to assail begun, all vows and consecrations giving place: o most potential love! vow, bond, nor space, 265 in thee hath neither sting, knot, nor confine, for thou art all, and all things else are thine. 'when thou impressest, what are precepts worth of stale example? when thou wilt inflame, how coldly those impediments stand forth 270 of wealth, of filial fear, law, kindred, fame! love's arms are peace, 'gainst rule, 'gainst sense, 'gainst shame, and sweetens, in the suffering pangs it bears, the aloes of all forces, shocks, and fears. 275 'now all these hearts that do on mine depend, feeling it break, with bleeding groans they pine; and supplicant their sighs to you extend, to leave the battery that you make 'gainst mine, lending soft audience to my sweet design, 280 and credent soul to that strong-bonded oath that shall prefer and undertake my troth.' 'this said, his watery eyes he did dismount, whose sights till then were levell'd on my face; each cheek a river running from a fount 285 with brinish current downward flow'd apace: o, how the channel to the stream gave grace! who glazed with crystal gate the glowing roses that flame through water which their hue encloses. 'o father, what a hell of witchcraft lies 290 in the small orb of one particular tear! but with the inundation of the eyes what rocky heart to water will not wear? what breast so cold that is not warmed here? o cleft effect! cold modesty, hot wrath, 295 both fire from hence and chill extincture hath. 'for, lo, his passion, but an art of craft, even there resolved my reason into tears; there my white stole of chastity i daff'd, shook off my sober guards and civil fears; 300 appear to him, as he to me appears, all melting; though our drops this difference bore, his poison'd me, and mine did him restore. 'in him a plenitude of subtle matter, applied to cautels, all strange forms receives, 305 of burning blushes, or of weeping water, or swooning paleness; and he takes and leaves, in either's aptness, as it best deceives, to blush at speeches rank to weep at woes, or to turn white and swoon at tragic shows. 310 'that not a heart which in his level came could 'scape the hail of his all-hurting aim, showing fair nature is both kind and tame; and, veil'd in them, did win whom he would maim: against the thing he sought he would exclaim; 315 when he most burn'd in heart-wish'd luxury, he preach'd pure maid, and praised cold chastity. 'thus merely with the garment of a grace the naked and concealed fiend he cover'd; that th' unexperient gave the tempter place, 320 which like a cherubin above them hover'd. who, young and simple, would not be so lover'd? ay me! i fell; and yet do question make what i should do again for such a sake. 'o, that infected moisture of his eye, 325 o, that false fire which in his cheek so glow'd, o, that forced thunder from his heart did fly, o, that sad breath his spongy lungs bestow'd, o, all that borrow'd motion seeming owed, would yet again betray the fore-betray'd, 330 and new pervert a reconciled maid!' \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "4M2GJmZpUBV3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sO0IYDULULZD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_length=10\n",
        "vocab= len(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SLzz0ROUkws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "65b06e87-41cc-4839-e35a-3537c91e5865"
      },
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "1ORakrZjUNPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequences=[]\n",
        "y=[]\n",
        "for i in range(len(text)):\n",
        "  if i+seq_length>=len(text):\n",
        "    break\n",
        "  sequences.append(text[i:i+seq_length])\n",
        "  y.append(text[i+seq_length])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "21ELSe08VWLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9b765f24-2052-4433-e718-0935d0942773"
      },
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14534"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "y7ptnlWuVYkn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "for seq in sequences:\n",
        "  tmp=[]\n",
        "  for i in seq:\n",
        "    tmp.append(char_to_int[i])\n",
        "  X.append(tmp)\n",
        "  \n",
        "Y=[]\n",
        "for i in y:\n",
        "  Y.append(char_to_int[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "80YNVVbPVoaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "9d256170-3ca0-4386-d70c-c9dfbade467e"
      },
      "cell_type": "code",
      "source": [
        "X[:6]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 0, 30, 33, 40, 23, 36, 2, 37, 0],\n",
              " [0, 30, 33, 40, 23, 36, 2, 37, 0, 21],\n",
              " [30, 33, 40, 23, 36, 2, 37, 0, 21, 33],\n",
              " [33, 40, 23, 36, 2, 37, 0, 21, 33, 31],\n",
              " [40, 23, 36, 2, 37, 0, 21, 33, 31, 34],\n",
              " [23, 36, 2, 37, 0, 21, 33, 31, 34, 30]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "Ll8mLhodWS8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "datax = np_utils.to_categorical(X)\n",
        "datay = np_utils.to_categorical(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iq3zqTx6W_X5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b12c2193-9847-49b1-e2de-3df784f5ab17"
      },
      "cell_type": "code",
      "source": [
        "len(datax[0][0])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "-aZS1qKsXFLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "afceb915-4eae-4274-f5e3-ae7236934b44"
      },
      "cell_type": "code",
      "source": [
        "datay.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14534, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "Ilhe4fNVXVK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5ad937c6-aa15-4742-de0b-aa95e10cc106"
      },
      "cell_type": "code",
      "source": [
        "datax.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14534"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "Jl7liupoXjzP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRgBBUfkYNWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3379
        },
        "outputId": "e0735e88-711d-4bcf-f57a-d85d7b1aef9e"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(datax.shape[1], datax.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(datay.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "filepath=\"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(datax, datay, epochs=50, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "14534/14534 [==============================] - 15s 1ms/step - loss: 3.0202\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.02016, saving model to weights.hdf5\n",
            "Epoch 2/50\n",
            "14534/14534 [==============================] - 13s 874us/step - loss: 2.6179\n",
            "\n",
            "Epoch 00002: loss improved from 3.02016 to 2.61789, saving model to weights.hdf5\n",
            "Epoch 3/50\n",
            "14534/14534 [==============================] - 13s 875us/step - loss: 2.3671\n",
            "\n",
            "Epoch 00003: loss improved from 2.61789 to 2.36705, saving model to weights.hdf5\n",
            "Epoch 4/50\n",
            "14534/14534 [==============================] - 13s 874us/step - loss: 2.2422\n",
            "\n",
            "Epoch 00004: loss improved from 2.36705 to 2.24218, saving model to weights.hdf5\n",
            "Epoch 5/50\n",
            "14534/14534 [==============================] - 13s 866us/step - loss: 2.1549\n",
            "\n",
            "Epoch 00005: loss improved from 2.24218 to 2.15488, saving model to weights.hdf5\n",
            "Epoch 6/50\n",
            "14534/14534 [==============================] - 13s 867us/step - loss: 2.0660\n",
            "\n",
            "Epoch 00006: loss improved from 2.15488 to 2.06598, saving model to weights.hdf5\n",
            "Epoch 7/50\n",
            "14534/14534 [==============================] - 13s 864us/step - loss: 1.9903\n",
            "\n",
            "Epoch 00007: loss improved from 2.06598 to 1.99027, saving model to weights.hdf5\n",
            "Epoch 8/50\n",
            "14534/14534 [==============================] - 13s 863us/step - loss: 1.9239\n",
            "\n",
            "Epoch 00008: loss improved from 1.99027 to 1.92386, saving model to weights.hdf5\n",
            "Epoch 9/50\n",
            "14534/14534 [==============================] - 13s 881us/step - loss: 1.8530\n",
            "\n",
            "Epoch 00009: loss improved from 1.92386 to 1.85300, saving model to weights.hdf5\n",
            "Epoch 10/50\n",
            "14534/14534 [==============================] - 13s 869us/step - loss: 1.7832\n",
            "\n",
            "Epoch 00010: loss improved from 1.85300 to 1.78317, saving model to weights.hdf5\n",
            "Epoch 11/50\n",
            "14534/14534 [==============================] - 13s 863us/step - loss: 1.7102\n",
            "\n",
            "Epoch 00011: loss improved from 1.78317 to 1.71022, saving model to weights.hdf5\n",
            "Epoch 12/50\n",
            "14534/14534 [==============================] - 13s 864us/step - loss: 1.6352\n",
            "\n",
            "Epoch 00012: loss improved from 1.71022 to 1.63518, saving model to weights.hdf5\n",
            "Epoch 13/50\n",
            "14534/14534 [==============================] - 13s 885us/step - loss: 1.5494\n",
            "\n",
            "Epoch 00013: loss improved from 1.63518 to 1.54944, saving model to weights.hdf5\n",
            "Epoch 14/50\n",
            "14534/14534 [==============================] - 13s 880us/step - loss: 1.4504\n",
            "\n",
            "Epoch 00014: loss improved from 1.54944 to 1.45036, saving model to weights.hdf5\n",
            "Epoch 15/50\n",
            "14534/14534 [==============================] - 13s 878us/step - loss: 1.3606\n",
            "\n",
            "Epoch 00015: loss improved from 1.45036 to 1.36059, saving model to weights.hdf5\n",
            "Epoch 16/50\n",
            "14534/14534 [==============================] - 13s 867us/step - loss: 1.2637\n",
            "\n",
            "Epoch 00016: loss improved from 1.36059 to 1.26366, saving model to weights.hdf5\n",
            "Epoch 17/50\n",
            "14534/14534 [==============================] - 13s 873us/step - loss: 1.1523\n",
            "\n",
            "Epoch 00017: loss improved from 1.26366 to 1.15225, saving model to weights.hdf5\n",
            "Epoch 18/50\n",
            "14534/14534 [==============================] - 12s 859us/step - loss: 1.0464\n",
            "\n",
            "Epoch 00018: loss improved from 1.15225 to 1.04638, saving model to weights.hdf5\n",
            "Epoch 19/50\n",
            "14534/14534 [==============================] - 12s 855us/step - loss: 0.9435\n",
            "\n",
            "Epoch 00019: loss improved from 1.04638 to 0.94354, saving model to weights.hdf5\n",
            "Epoch 20/50\n",
            "14534/14534 [==============================] - 12s 854us/step - loss: 0.8324\n",
            "\n",
            "Epoch 00020: loss improved from 0.94354 to 0.83242, saving model to weights.hdf5\n",
            "Epoch 21/50\n",
            "14534/14534 [==============================] - 12s 858us/step - loss: 0.7508\n",
            "\n",
            "Epoch 00021: loss improved from 0.83242 to 0.75084, saving model to weights.hdf5\n",
            "Epoch 22/50\n",
            "14534/14534 [==============================] - 12s 843us/step - loss: 0.6497\n",
            "\n",
            "Epoch 00022: loss improved from 0.75084 to 0.64972, saving model to weights.hdf5\n",
            "Epoch 23/50\n",
            "14534/14534 [==============================] - 13s 864us/step - loss: 0.5780\n",
            "\n",
            "Epoch 00023: loss improved from 0.64972 to 0.57801, saving model to weights.hdf5\n",
            "Epoch 24/50\n",
            "14534/14534 [==============================] - 13s 865us/step - loss: 0.4988\n",
            "\n",
            "Epoch 00024: loss improved from 0.57801 to 0.49880, saving model to weights.hdf5\n",
            "Epoch 25/50\n",
            "14534/14534 [==============================] - 12s 857us/step - loss: 0.4383\n",
            "\n",
            "Epoch 00025: loss improved from 0.49880 to 0.43830, saving model to weights.hdf5\n",
            "Epoch 26/50\n",
            "14534/14534 [==============================] - 13s 866us/step - loss: 0.3776\n",
            "\n",
            "Epoch 00026: loss improved from 0.43830 to 0.37765, saving model to weights.hdf5\n",
            "Epoch 27/50\n",
            "14534/14534 [==============================] - 12s 856us/step - loss: 0.3340\n",
            "\n",
            "Epoch 00027: loss improved from 0.37765 to 0.33398, saving model to weights.hdf5\n",
            "Epoch 28/50\n",
            "14534/14534 [==============================] - 13s 877us/step - loss: 0.3062\n",
            "\n",
            "Epoch 00028: loss improved from 0.33398 to 0.30617, saving model to weights.hdf5\n",
            "Epoch 29/50\n",
            "14534/14534 [==============================] - 13s 871us/step - loss: 0.2558\n",
            "\n",
            "Epoch 00029: loss improved from 0.30617 to 0.25581, saving model to weights.hdf5\n",
            "Epoch 30/50\n",
            "14534/14534 [==============================] - 13s 869us/step - loss: 0.2245\n",
            "\n",
            "Epoch 00030: loss improved from 0.25581 to 0.22453, saving model to weights.hdf5\n",
            "Epoch 31/50\n",
            "14534/14534 [==============================] - 13s 879us/step - loss: 0.2006\n",
            "\n",
            "Epoch 00031: loss improved from 0.22453 to 0.20059, saving model to weights.hdf5\n",
            "Epoch 32/50\n",
            "14534/14534 [==============================] - 13s 886us/step - loss: 0.2085\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.20059\n",
            "Epoch 33/50\n",
            "14534/14534 [==============================] - 12s 857us/step - loss: 0.1887\n",
            "\n",
            "Epoch 00033: loss improved from 0.20059 to 0.18870, saving model to weights.hdf5\n",
            "Epoch 34/50\n",
            "14534/14534 [==============================] - 13s 877us/step - loss: 0.1702\n",
            "\n",
            "Epoch 00034: loss improved from 0.18870 to 0.17024, saving model to weights.hdf5\n",
            "Epoch 35/50\n",
            "14534/14534 [==============================] - 13s 870us/step - loss: 0.1564\n",
            "\n",
            "Epoch 00035: loss improved from 0.17024 to 0.15639, saving model to weights.hdf5\n",
            "Epoch 36/50\n",
            "14534/14534 [==============================] - 13s 864us/step - loss: 0.1466\n",
            "\n",
            "Epoch 00036: loss improved from 0.15639 to 0.14663, saving model to weights.hdf5\n",
            "Epoch 37/50\n",
            "14534/14534 [==============================] - 13s 870us/step - loss: 0.1417\n",
            "\n",
            "Epoch 00037: loss improved from 0.14663 to 0.14172, saving model to weights.hdf5\n",
            "Epoch 38/50\n",
            "14534/14534 [==============================] - 13s 864us/step - loss: 0.1520\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.14172\n",
            "Epoch 39/50\n",
            "14534/14534 [==============================] - 12s 846us/step - loss: 0.1425\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.14172\n",
            "Epoch 40/50\n",
            "14534/14534 [==============================] - 12s 854us/step - loss: 0.1295\n",
            "\n",
            "Epoch 00040: loss improved from 0.14172 to 0.12954, saving model to weights.hdf5\n",
            "Epoch 41/50\n",
            "14534/14534 [==============================] - 13s 875us/step - loss: 0.1237\n",
            "\n",
            "Epoch 00041: loss improved from 0.12954 to 0.12373, saving model to weights.hdf5\n",
            "Epoch 42/50\n",
            "14534/14534 [==============================] - 13s 871us/step - loss: 0.1324\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.12373\n",
            "Epoch 43/50\n",
            "14534/14534 [==============================] - 12s 859us/step - loss: 0.1177\n",
            "\n",
            "Epoch 00043: loss improved from 0.12373 to 0.11771, saving model to weights.hdf5\n",
            "Epoch 44/50\n",
            "14534/14534 [==============================] - 13s 873us/step - loss: 0.1133\n",
            "\n",
            "Epoch 00044: loss improved from 0.11771 to 0.11333, saving model to weights.hdf5\n",
            "Epoch 45/50\n",
            "14534/14534 [==============================] - 12s 855us/step - loss: 0.0960\n",
            "\n",
            "Epoch 00045: loss improved from 0.11333 to 0.09599, saving model to weights.hdf5\n",
            "Epoch 46/50\n",
            "14534/14534 [==============================] - 13s 864us/step - loss: 0.0954\n",
            "\n",
            "Epoch 00046: loss improved from 0.09599 to 0.09542, saving model to weights.hdf5\n",
            "Epoch 47/50\n",
            "14534/14534 [==============================] - 13s 870us/step - loss: 0.1021\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.09542\n",
            "Epoch 48/50\n",
            "14534/14534 [==============================] - 12s 859us/step - loss: 0.1075\n",
            "\n",
            "Epoch 00048: loss did not improve from 0.09542\n",
            "Epoch 49/50\n",
            "14534/14534 [==============================] - 12s 858us/step - loss: 0.1009\n",
            "\n",
            "Epoch 00049: loss did not improve from 0.09542\n",
            "Epoch 50/50\n",
            "14534/14534 [==============================] - 12s 849us/step - loss: 0.1144\n",
            "\n",
            "Epoch 00050: loss did not improve from 0.09542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1214d92ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "yc60JUnQY-x8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2e506dd2-4d99-410f-fae2-705cc107aa7a"
      },
      "cell_type": "code",
      "source": [
        "tstr=\"give me a \"\n",
        "print(tstr,end='')\n",
        "for i in range(1000):\n",
        "  test=[]\n",
        "  for i in tstr:\n",
        "    test.append(char_to_int[i])\n",
        "\n",
        "  test= np_utils.to_categorical(test,num_classes=vocab)\n",
        "  test= test.reshape(1,test.shape[0],test.shape[1])\n",
        "  ans= model.predict(test)\n",
        "  pp=chars[numpy.argmax(ans)]\n",
        "  print(pp,end='')\n",
        "  tstr+=pp\n",
        "  tstr=tstr[1:]\n",
        "  \n",
        "  "
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "give me a several fair, their kind acceptance weepingly beseech'd, with the inundation of the wind upon his chin; his phoenix down began but to appear like unshorn velvet on that termless skin whose bare out-bragg'd the web it seem'd to wear: 95 yet show'd his visage by that cost more dear; and nice affections woeld veir a sare the fromived harm was sent me from a nun, or sister sanctified, of holiest note; which late her noble suit in court did shun, 235 whose rarest havings made the blossoms dote; for she was sought by spirits to attend this double voice accorded, and down i laid to list the sad-tuned tale; ere long espied a fickle maid full pale, 5 tearing of papers, breaking rings a-twain, storming her world with sorrow's wind and rain. upon her head a platted hive of straw, which fortified her visage from the sun, whereon the thought might think sometime diverted their poor balls are tied to the orbed earth; sometimes they do extend 25 their view right on; anon their gazes lend to every pla"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p_x1kbq4dymd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F-2ZWBnycACJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aSJlWQ3rdkAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "0d8fb944-318d-4949-d8e4-78334b237b1b"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "hVsAYf61d-Hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}